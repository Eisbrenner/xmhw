{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detecting marine heatwave events with xmhw**<br>\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import datetime  # this is needed to run original code\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need this if running original otherwise it really slows down\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import functions from xmhw**<br><br>\n",
    "We separated the calculation of the the climatologies from the identification of marine heat waves (mhw). In this way we have two separate functions and you can save a re-use the threshold while experimenting with different settings for the detection part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from xmhw.xmhw import threshold, detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting up dask**<br>\n",
    "\n",
    "I am not dask expert, this is something I tried to make the code run faster and making sure that cell grids are processed in parallel. I use dask.delayed to create delayed functions and that speed up the calculation. It also helps computing the threshold before the detection step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the dask scheduler to threaded.\n",
    "# The threaded scheduler executes computations with a local multiprocessing.pool.ThreadPool \n",
    "# so you can run multithread \n",
    "dask.config.set(scheduler='threads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the functions as delayed functions\n",
    "threshold = dask.delayed(threshold)\n",
    "detect = dask.delayed(detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ProgressBar to help with diagnostic\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example calculation**<br>\n",
    "\n",
    "Using NOAA OISST timeseries, I am selecting a smaller region to demo xmhw code.<br>\n",
    "Before calculaitng anything the function land_check() (from xmhw.identify) is called. This function does has two steps:<br>\n",
    "  - stacks all dimensions but \"time\" in a new 'cell' dimension;\n",
    "  - removes all the land points, these are assumed to have np.nan values along the time axis\n",
    "   \n",
    "NB If the timeseries you want to use has a time axis which is not called 'time' you can specify that.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# using NOAA oisst as timeseries\n",
    "ds =xr.open_mfdataset('/g/data/ua8/NOAA_OISST/AVHRR/v2-1_modified/timeseries/oisst_timeseries_*.nc',\n",
    "                        concat_dim='time', combine='nested', chunks={'time':-1, 'lat': 10, 'lon': 10})\n",
    "# removing zlev dimension\n",
    "sst =ds['sst'].squeeze()\n",
    "sst = sst.drop('zlev')\n",
    "# for the moment getting small region to test\n",
    "# This correspond to ... ocean cell grid points\n",
    "tos = sst.sel(lat=slice(-44,-41),lon=slice(144, 149))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is small enough to have 1 chunk)\n",
    "# NB for each cell the timeseries should be in same chunk, fo this reason chunk({'time-dimension': -1}) \n",
    "# is included n the module where necessary\n",
    "ts = tos.chunk({'time':-1, 'lat':-1, 'lon':-1})\n",
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate threshold separately and save it to file**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The *threshold* function will calculate the climatologies, ie.e seasonal average and threhsold, then use to detect marine heat waves (mhw) along the timeseries.<br>This function mimic the original code behaviour including returning a dictionary. We are looking at changing this so it will return a dataset instead.<br> As for the original several parameters can be set:\n",
    "````\n",
    "threshold(temp, tdim='time', climatologyPeriod=[None,None], pctile=90, windowHalfWidth=5,\n",
    "          smoothPercentile=True, smoothPercentileWidth=31, maxPadLength=False, coldSpells=False, Ly=False)\n",
    "````\n",
    "Where *temp* is the temperature timeseries, this is the only input needed, if you're happy with the default settings and if you're time dimension is called 'time'.<br><br>\n",
    "In the following example we're using all default settings for threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this won't do anything until we call compute(), because we are using delayed\n",
    "clim = threshold(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    clim_dict = clim.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to notice that differently from the original function which takes a numpy 1D array, because we are using xarray we can pass a 3D array (in fact we could pass any n-dim array) and the code will deal with it.<br>\n",
    "We selected a 12X20 lat-lon region and of these 135 grid cells are ocean. <br>\n",
    "\n",
    "Before saving the results to netcdf the data should be *unstacked*. For threshold() the dataset is unstacked before being returned.<br> \n",
    "Differently from the original function, here the climatologies are saved not along the entire timeseries but only along the new *doy* dimension. Given that xarray keeps the coordinates with the arrays there is no need to repeat the climatologies along the time axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# save threshold and seasonal average to netcdf\n",
    "climds = xr.merge([clim_dict['thresh'], clim_dict['seas']])\n",
    "climds.to_netcdf('climatology_tas.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter MHW passing calculated climatologies to detect**<br>\n",
    "The *detect* function indetifies all the mhw events and their characteristics. Corresponds to the second part of the original detect function and again mimic the logic of the original code.\n",
    "\n",
    "````\n",
    "    detect(temp, thresh, seas, minDuration=5, joinAcrossGaps=True, maxGap=2,\n",
    "           maxPadLength=None, coldSpells=False, tdim='time')\n",
    "````\n",
    "This time you have to pass the timeseries, the threshold and the seasonal average. The others parameters are optional.<br> The results are stored differently form the original function:\n",
    "````\n",
    "   Original structure: \n",
    "       - mhw is a dictionary\n",
    "       - each characteristic is a key with a list of values, each value represent an event\n",
    "       - Ex.  mhw['intensity_max'][ev]\n",
    "````\n",
    "First of all, the new function returns an xarray dataset not a dictionary. Most importantly, there's one variable for each calculated field. The events are stored all together not as separate arrays.<br> Let's see an example, we are using all default settings for MHW filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as before this won't do anything until I call compute()\n",
    "mhw  = detect(tos, clim_dict['thresh'], clim_dict['seas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    ds = mhw.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the function returns a xarray dataset, 'cell' dimension is still present, so we need to unstack it if we want back the latitude and longitude grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mhwds = ds.unstack('cell')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataset has two kind of variables:\n",
    "````events (time, lat, lon)\n",
    "    relSeas (time, lat, lon)\n",
    "    relThresh (time, lat, lon)\n",
    "    end_idx (event, lat, lon)\n",
    "    start_idx (event, lat, lon)\n",
    "    intensity_cumulative (event, lat, lon)\n",
    "\n",
    "````\n",
    "Some are defined on along time and they will have np.nan everywhere but where an event is defined. \"events' is one of them it will look like:<br>\n",
    "  nan, nan, nan, 3, 3, 3, 3, 3, nan ... <br>\n",
    "Where 3 is the index of the first timestep for an event.\n",
    "The *events* variable can be used as a coordinate for the other variables defined along the time axis.\n",
    "The other group defines the mhw characteristics and they are defined along the *event* dimension.\n",
    "The *event* dimension size is determined by the number of separate events individuated. Separate events have different startung times. This menas that if two different cells have events starting at timestep=50, these event will have the same index along the dimension 'event' regardless on their duration.<br>\n",
    "Clearly this is an approximation because if an event starts even a timestep later is classified as separate.\n",
    "This is because as for the orgiinal code, each event is individuated cell by cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mhwds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mhw.intensity_cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save mhw to yearly netcdf files (to split size if you have a really long timeseries)\n",
    "#years, datasets = zip(*mhwds.groupby(\"time.year\"))\n",
    "#paths = [\"mhw_%s.nc\" % y for y in years]\n",
    "#xr.save_mfdataset(datasets, paths)\n",
    "# you can use this if only doing a subset\n",
    "\n",
    "mhwds.to_netcdf('mhw.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find MHW using original code**<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#from datetime import date\n",
    "#from marineHeatWaves import detect as orig_detect\n",
    "\n",
    "# create necessary time numpy array\n",
    "t = np.arange(date(1981,9,1).toordinal(),date(2020,5,18).toordinal()+1)\n",
    "sst = tos[:,0,0].squeeze().values\n",
    "# call function with default settings\n",
    "orig_mhw, orig_clim = orig_detect(t, sst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-20.10] *",
   "language": "python",
   "name": "conda-env-analysis3-20.10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
